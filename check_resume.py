import sys
from pathlib import Path
from app.parsing.resume import ResumeParser
from app.parsing.models import PageType, DataQuality

# –£—Å—Ç–æ–π—á–∏–≤–æ–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ –∫–æ—Ä–Ω—è
try:
    PROJECT_ROOT = Path(__file__).resolve().parent
    FIXTURE_PATH = PROJECT_ROOT / "tests" / "fixtures" / "raw" / "resume_ok_full_profile.html"
    if not FIXTURE_PATH.exists():
        PROJECT_ROOT = Path(__file__).resolve().parents[1]
        FIXTURE_PATH = PROJECT_ROOT / "tests" / "fixtures" / "raw" / "resume_ok_full_profile.html"
except IndexError:
    pass

def run_test():
    print(f"üõ°Ô∏è  Testing Resume Parser on {FIXTURE_PATH.name}...")
    
    if not FIXTURE_PATH.exists():
        print(f"‚ùå Fixture not found at {FIXTURE_PATH}")
        sys.exit(1)
        
    content = FIXTURE_PATH.read_bytes()
    
    # 1. –¢–µ—Å—Ç —Å "–≥—Ä—è–∑–Ω—ã–º" URL (–ø–∞—Ä–∞–º–µ—Ç—Ä—ã, –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ —Å–ª—ç—à–∞)
    # ID –∏–∑ —Ñ–∞–π–ª–∞ –æ—Ç—á–µ—Ç–∞: 7502793
    dirty_url = "https://work.ua/resumes/7502793?utm_source=test"
    
    parser = ResumeParser(content, dirty_url)
    result = parser.parse()
    
    # --- Assertions ---
    
    # 1. Quality
    if result.quality != DataQuality.COMPLETE:
        print(f"‚ùå Low Quality: {result.quality} | Msg: {result.error_message}")
        sys.exit(1)
    
    # 2. Canonical URL Check (Critical)
    expected_url = "https://www.work.ua/resumes/7502793/"
    
    if result.url != expected_url:
        print(f"‚ùå ParsingResult.url NOT canonical: {result.url}")
        sys.exit(1)
    if result.payload.url != expected_url:
        print(f"‚ùå Payload.url NOT canonical: {result.payload.url}")
        sys.exit(1)
        
    print(f"‚úÖ URL Canonicalized: {result.url}")

    data = result.payload
    
    # 3. Experience & Garbage Check
    print(f"‚úÖ Experience Entries: {len(data.experience)}")
    if len(data.experience) == 0:
        print("‚ùå No experience entries parsed from resume_ok_full_profile.html (regression).")
        sys.exit(1)

    for exp in data.experience:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –Ω–µ –∑–∞—Ö–≤–∞—Ç–∏–ª–∏ –∑–∞–≥–æ–ª–æ–≤–∫–∏ "–°—Ö–æ–∂–∏–µ –∫–∞–Ω–¥–∏–¥–∞—Ç—ã" –∏ —Ç.–ø.
        pos_lower = (exp.position or "").lower()
        if any(x in pos_lower for x in ["–∫–∞–Ω–¥–∏–¥–∞—Ç", "–∫–∞–Ω–¥–∏–¥–∞—Ç–∏", "—ñ–Ω—à—ñ", "—Å—Ö–æ–∂—ñ", "–¥–æ–¥–∞—Ç–∫–æ–≤–∞", "–∫–æ–Ω—Ç–∞–∫—Ç–Ω–∞"]):
            print(f"‚ùå Garbage in Experience: Found '{exp.position}'")
            sys.exit(1)
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏—è –æ–±—Ä–µ–∑–∫–∏ (–¥–ª–∏–Ω–∞ > 100 –¥–ª—è –¥–ª–∏–Ω–Ω—ã—Ö –Ω–∞–∑–≤–∞–Ω–∏–π)
        if exp.company and len(exp.company) > 99:
             print(f"   ‚ÑπÔ∏è  Long company name preserved ({len(exp.company)} chars)")

    if len(data.experience) > 0:
        first = data.experience[0]
        print(f"   Sample Job: '{first.position}' @ '{first.company}'")

    print(f"‚úÖ Education Entries: {len(data.education)}")
    print(f"‚úÖ Skills Found: {len(data.skills)}")
    # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –Ω–∞–ø–æ–ª–Ω–µ–Ω–Ω–æ—Å—Ç—å: –Ω–∞ –ø–æ–ª–Ω–æ—Ü–µ–Ω–Ω–æ–º –ø—Ä–æ—Ñ–∏–ª–µ –æ–∂–∏–¥–∞–µ–º —Ö–æ—Ç—è –±—ã 1 –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∏ —Ö–æ—Ç—è –±—ã 1 –Ω–∞–≤—ã–∫.
    # –ï—Å–ª–∏ –æ–¥–Ω–æ –∏–∑ –Ω–∏—Ö –ø—É—Å—Ç–æ–µ ‚Äî –≤–µ—Ä–æ—è—Ç–Ω–æ, —Å–ª–æ–º–∞–ª–∏—Å—å —Å–µ–ª–µ–∫—Ç–æ—Ä—ã/—Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ.
    if len(data.education) == 0:
        print("‚ùå No education entries parsed (regression).")
        sys.exit(1)

    if len(data.skills) == 0:
        print("‚ùå No skills parsed (regression). Check CSS.SKILL_TAGS or page scope.")
        sys.exit(1)

    print("\nüéâ Resume Parser is functional!")

if __name__ == "__main__":
    run_test()