5: Локальный Оркестратор (Service Layer). Сборка MVP
Тема: Локальный Оркестратор (Service Layer). Сборка MVP. Статус: ✅ ВЫПОЛНЕНО ПОЛНОСТЬЮ
Ниже представлен детальный отчет о реализации архитектуры локального краулера, который служит фундаментом для следующего этапа (L6).

1. Search URL Builder (Генерация ссылок)
Файл: app/services/url_builder.py Реализованная логика:
Транслитерация: Реализован маппинг кириллических названий городов в слаги Work.ua (например, "Киев" -> "kyiv"). Для неизвестных городов применяется автоматическая транслитерация.
Параметризация: Метод build(query, city, params) поддерживает сложные фильтры Work.ua.
Списки значений кодируются через + (напр. category=1+17).
Составные кортежи (язык-уровень) кодируются через дефис (напр. 1-5).
Нормализация: Метод normalize(url) удаляет UTM-метки, приводит домен к www.work.ua и сортирует параметры запроса для гарантии каноничности (критично для дедупликации URL).
2. Local Repository (Слой хранения)
Файл: app/storage/repository.py Реализованная логика:
Формат: JSONL (New-line Delimited JSON).
Метод сохранения: save_result(result: ParsingResult).
Важно: Метод принимает объект ParsingResult, а не DTO напрямую. Внутри происходит извлечение payload.
Дедупликация: In-memory set (_seen_ids). При инициализации класс читает файл candidates.jsonl и восстанавливает множество уже скачанных ID.
Устойчивость: Используется flush() после каждой записи строки, чтобы предотвратить потерю данных при прерывании скрипта (Ctrl+C).
3. CrawlerService (Оркестрация)
Файл: app/services/crawler.py Реализованная логика:
Цикл: SERP Request → Parse Preview → Filter (Dedup) → Detail Request → Parse Detail → Save.
Троттлинг: Жестко заданные задержки DELAY_SERP (3.0с) и DELAY_DETAIL (1.5с) для работы в "белом" режиме без прокси.
Безопасность (Safety Checks):
Использует BaseParser для предварительной проверки HTML перед основным парсингом.
При обнаружении PageType.BAN, CAPTCHA или LOGIN сессия немедленно завершается (critical stop).
Пустые ответы от fetcher обрабатываются как ошибки, не ломая цикл.
Транспорт: Использует SmartFetcher (см. ниже), ожидая от него возврата str (HTML контента).
4. Точка входа (CLI)
Файл: main.py Файл транспорта: app/transport/fetcher.py (Создан в финале этапа) Реализованная логика:
CLI: Аргументы --query, --city, --pages, --out через argparse.
Fetcher: Реализован класс SmartFetcher на базе requests.
Возвращает str (защита от None).
Игнорирует HTTP 403/404 (не вызывает exception), позволяя парсеру обработать контент (так как Work.ua может отдавать капчу с кодом 200 или 403).
Observability: В конце работы выводится сводка CrawlStats (обработано страниц, найдено, сохранено, ошибок).